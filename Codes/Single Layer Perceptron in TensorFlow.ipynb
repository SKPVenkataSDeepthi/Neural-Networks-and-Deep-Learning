{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8105bf-23e9-48c4-b5f6-689f392fb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fd8fe38-7b18-45c8-9c72-c10d5d0a36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the dataset using “Keras” from the imported version of tensor flow.\n",
    "(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c4dcf57-3f5c-41c0-a9f4-edf12c23600e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x30eb23740>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display the shape and image of the single image in the dataset. The image size contains a 28*28 matrix and length of the training set is 60,000 and the testing set is 10,000.\n",
    "len(x_train) \n",
    "len(x_test) \n",
    "x_train[0].shape \n",
    "plt.matshow(x_train[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17c68a1-bdc1-4d77-bcd6-ba8745a2f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now normalize the dataset in order to compute the calculations in a fast and accurate manner.\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "# Flatting the dataset in order \n",
    "# to compute for model building \n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28) \n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffac1ce2-38e3-455a-b4fa-c208674863c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 216us/step - accuracy: 0.8203 - loss: 0.7079\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step - accuracy: 0.9162 - loss: 0.3056\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211us/step - accuracy: 0.9198 - loss: 0.2870\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step - accuracy: 0.9242 - loss: 0.2769\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step - accuracy: 0.9276 - loss: 0.2647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30eb82e40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Building a neural network with single-layer perception. \n",
    "model = keras.Sequential([ \n",
    "\tkeras.layers.Dense(10, input_shape=(784,), \n",
    "\t\t\t\t\tactivation='sigmoid') \n",
    "]) \n",
    "model.compile( \n",
    "\toptimizer='adam', \n",
    "\tloss='sparse_categorical_crossentropy', \n",
    "\tmetrics=['accuracy']) \n",
    "\n",
    "model.fit(x_train_flatten, y_train, epochs=5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e34e1d05-526b-44e1-8194-ca7fab2424c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184us/step - accuracy: 0.9141 - loss: 0.3030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26748377084732056, 0.9254999756813049]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## output of the accuracy model\n",
    "model.evaluate(x_test_flatten, y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad4053-4c1e-4b2d-aed9-8759980b7da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
